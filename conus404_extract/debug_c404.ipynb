{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T22:24:08.183540Z",
     "iopub.status.busy": "2024-11-28T22:24:08.183321Z",
     "iopub.status.idle": "2024-11-28T22:24:08.913543Z",
     "shell.execute_reply": "2024-11-28T22:24:08.913071Z",
     "shell.execute_reply.started": "2024-11-28T22:24:08.183523Z"
    }
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "import logging\n",
    "import os\n",
    "import intake\n",
    "import concurrent.futures\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import dask\n",
    "import zarr\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import pyproj\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7878a77d059eb84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T22:24:08.914503Z",
     "iopub.status.busy": "2024-11-28T22:24:08.914042Z",
     "iopub.status.idle": "2024-11-28T22:24:08.917302Z",
     "shell.execute_reply": "2024-11-28T22:24:08.916968Z",
     "shell.execute_reply.started": "2024-11-28T22:24:08.914486Z"
    }
   },
   "outputs": [],
   "source": [
    "r = '/caldera/hovenweep/projects/usgs/water'\n",
    "d = os.path.join(r, 'wymtwsc', 'dketchum')\n",
    "c404 = os.path.join(d, 'conus404')\n",
    "dads = os.path.join(d, 'dads')\n",
    "ghcn = os.path.join(d, 'climate', 'ghcn')\n",
    "\n",
    "zarr_store = os.path.join(r, 'impd/hytest/conus404/conus404_hourly.zarr')\n",
    "sites = os.path.join(dads, 'met', 'stations', 'madis_29OCT2024.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48c2b689-5222-4ab8-afb4-91e4ba03cd86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T22:24:09.707404Z",
     "iopub.status.busy": "2024-11-28T22:24:09.707069Z",
     "iopub.status.idle": "2024-11-28T22:24:09.710389Z",
     "shell.execute_reply": "2024-11-28T22:24:09.710042Z",
     "shell.execute_reply.started": "2024-11-28T22:24:09.707390Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_quadrants(b):\n",
    "    mid_longitude = (b[0] + b[2]) / 2\n",
    "    mid_latitude = (b[1] + b[3]) / 2\n",
    "    quadrant_nw = (b[0], mid_latitude, mid_longitude, b[3])\n",
    "    quadrant_ne = (mid_longitude, mid_latitude, b[2], b[3])\n",
    "    quadrant_sw = (b[0], b[1], mid_longitude, mid_latitude)\n",
    "    quadrant_se = (mid_longitude, b[1], b[2], mid_latitude)\n",
    "    quadrants = [quadrant_nw, quadrant_ne, quadrant_sw, quadrant_se]\n",
    "    return quadrants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b83913a5-eb03-4ff5-84d1-0ba3b16d3f41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T22:24:10.240519Z",
     "iopub.status.busy": "2024-11-28T22:24:10.240164Z",
     "iopub.status.idle": "2024-11-28T22:24:10.245294Z",
     "shell.execute_reply": "2024-11-28T22:24:10.244964Z",
     "shell.execute_reply.started": "2024-11-28T22:24:10.240504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-125.0, 46.0, -110.5, 53.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = (-125.0, 25.0, -67.0, 53.0)\n",
    "quadrants = get_quadrants(bounds)\n",
    "sixteens = [get_quadrants(q) for q in quadrants]\n",
    "sixteens = [x for xs in sixteens for x in xs]\n",
    "sixteens[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2205f6c4d297eac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T22:24:10.655833Z",
     "iopub.status.busy": "2024-11-28T22:24:10.655469Z",
     "iopub.status.idle": "2024-11-28T22:24:10.658297Z",
     "shell.execute_reply": "2024-11-28T22:24:10.657965Z",
     "shell.execute_reply.started": "2024-11-28T22:24:10.655804Z"
    }
   },
   "outputs": [],
   "source": [
    "stations = sites\n",
    "nc_data = zarr_store\n",
    "workers=36\n",
    "overwrite=False\n",
    "bounds=(-114.5, 46.5, -113.5, 47.5)\n",
    "start_yr=2014\n",
    "end_yr=2014\n",
    "mode = 'dask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74f3b53980cb32b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T22:24:11.519765Z",
     "iopub.status.busy": "2024-11-28T22:24:11.519410Z",
     "iopub.status.idle": "2024-11-28T22:24:11.573341Z",
     "shell.execute_reply": "2024-11-28T22:24:11.572940Z",
     "shell.execute_reply.started": "2024-11-28T22:24:11.519735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 stations to write\n",
      "sample stations for the selected region:\n",
      "          fid   latitude   longitude         elev      stype\n",
      "fid                                                        \n",
      "TR266  TR266  47.045933 -114.112076  1353.599976       RAWS\n",
      "MTNNM  MTNNM  47.022991 -114.388680   910.700012   utmesnet\n",
      "G2344  G2344  46.903332 -114.115669   961.030029  APRSWXNET\n",
      "AV610  AV610  46.526669 -114.047829  1164.000000  APRSWXNET\n",
      "FINM8  FINM8  47.045929 -114.112068  1353.599976       RAWS\n"
     ]
    }
   ],
   "source": [
    "station_list = pd.read_csv(stations)\n",
    "if 'LAT' in station_list.columns:\n",
    "    station_list = station_list.rename(columns={'STAID': 'fid', 'LAT': 'latitude', 'LON': 'longitude'})\n",
    "station_list.index = station_list['fid']\n",
    "\n",
    "if bounds:\n",
    "    w, s, e, n = bounds\n",
    "    station_list = station_list[(station_list['latitude'] < n) & (station_list['latitude'] >= s)]\n",
    "    station_list = station_list[(station_list['longitude'] < e) & (station_list['longitude'] >= w)]\n",
    "else:\n",
    "    ln = station_list.shape[0]\n",
    "    w, s, e, n = (-125.0, 25.0, -67.0, 53.0)\n",
    "    station_list = station_list[(station_list['latitude'] < n) & (station_list['latitude'] >= s)]\n",
    "    station_list = station_list[(station_list['longitude'] < e) & (station_list['longitude'] >= w)]\n",
    "    print('dropped {} stations outside NLDAS-2 extent'.format(ln - station_list.shape[0]))\n",
    "\n",
    "print(f'{len(station_list)} stations to write')\n",
    "print(f'sample stations for the selected region:\\n {station_list.sample(n=5)}')\n",
    "\n",
    "dates = [(year, month, calendar.monthrange(year, month)[-1])\n",
    "         for year in range(start_yr, end_yr + 1) for month in range(1, 13)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0a07bc3-75ee-4144-8ab6-b263df63dd47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T22:24:12.496142Z",
     "iopub.status.busy": "2024-11-28T22:24:12.495713Z",
     "iopub.status.idle": "2024-11-28T22:24:12.512895Z",
     "shell.execute_reply": "2024-11-28T22:24:12.512558Z",
     "shell.execute_reply.started": "2024-11-28T22:24:12.496124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1251436.5323012709,\n",
       " 929060.7052309539,\n",
       " -1157553.5378020902,\n",
       " 1023945.1012115715)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def projected_coords(row, _bounds=None, buffer=None):\n",
    "    globe = ccrs.Globe(ellipse='sphere', semimajor_axis=6370000, semiminor_axis=6370000)\n",
    "    lcc = ccrs.LambertConformal(globe=globe,\n",
    "                                central_longitude=-97.9000015258789,\n",
    "                                central_latitude=39.100006103515625,\n",
    "                                standard_parallels=[30.0, 50.0])\n",
    "    lcc_wkt = lcc.to_wkt()\n",
    "    source_crs = 'epsg:4326'\n",
    "    transformer = pyproj.Transformer.from_crs(source_crs, lcc_wkt)\n",
    "    if _bounds is not None:\n",
    "        west, south, east, north = _bounds\n",
    "        sw_x, sw_y = transformer.transform(south, west)\n",
    "        ne_x, ne_y = transformer.transform(north, east)\n",
    "        if buffer:\n",
    "            return sw_x - buffer, sw_y - buffer, ne_x + buffer, ne_y + buffer\n",
    "        else:\n",
    "            return sw_x, sw_y, ne_x, ne_y\n",
    "    else:\n",
    "        x, y = transformer.transform( row['latitude'], row['longitude'])\n",
    "        return x, y\n",
    "\n",
    "bounds_proj = projected_coords(None, _bounds=bounds)\n",
    "bounds_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "639d96ad-b66a-40d5-b19c-dbc6f0c83cf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T22:24:14.375141Z",
     "iopub.status.busy": "2024-11-28T22:24:14.374729Z",
     "iopub.status.idle": "2024-11-28T22:24:15.841323Z",
     "shell.execute_reply": "2024-11-28T22:24:15.840783Z",
     "shell.execute_reply.started": "2024-11-28T22:24:14.375110Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dketchum/miniconda3/envs/hyt/lib/python3.10/site-packages/intake_xarray/base.py:21: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  'dims': dict(self._ds.dims),\n"
     ]
    }
   ],
   "source": [
    "output_mode = 'ba'\n",
    "hytest_cat = intake.open_catalog(\n",
    "    \"https://raw.githubusercontent.com/hytest-org/hytest/main/dataset_catalog/hytest_intake_catalog.yml\")\n",
    "cat = hytest_cat['conus404-catalog']\n",
    "if output_mode == 'uncorrected':\n",
    "    # model output, uncorrected\n",
    "    dataset = 'conus404-hourly-onprem-hw'\n",
    "    out_data = csv_files = os.path.join(c404, 'station_data')\n",
    "elif output_mode == 'ba':\n",
    "    # bias-adjusted for precip and temp\n",
    "    dataset = 'conus404-hourly-ba-onprem-hw'\n",
    "    out_data = csv_files = os.path.join(c404, 'station_data_ba')\n",
    "else:\n",
    "    raise ValueError('output_mode not recognized')\n",
    "ds = cat[dataset].to_dask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c18acd2e838f671b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T22:24:17.208957Z",
     "iopub.status.busy": "2024-11-28T22:24:17.208394Z",
     "iopub.status.idle": "2024-11-28T22:24:17.219092Z",
     "shell.execute_reply": "2024-11-28T22:24:17.218628Z",
     "shell.execute_reply.started": "2024-11-28T22:24:17.208932Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_month_met(station_list_, date_, out_data, overwrite, bounds_=None, output_mode='uncorrected'):\n",
    "    \"\"\"\"\"\"\n",
    "    import xoak\n",
    "    year, month, month_end = date_\n",
    "\n",
    "    # dataset 1979 to 2022-10-01\n",
    "    if year == 2022 and month > 9:\n",
    "        return\n",
    "    date_string = '{}-{}'.format(year, str(month).rjust(2, '0'))\n",
    "\n",
    "    fids = station_list_.index.to_list()\n",
    "\n",
    "    hytest_cat = intake.open_catalog(\n",
    "        \"https://raw.githubusercontent.com/hytest-org/hytest/main/dataset_catalog/hytest_intake_catalog.yml\")\n",
    "    cat = hytest_cat['conus404-catalog']\n",
    "    if output_mode == 'uncorrected':\n",
    "        # model output, uncorrected\n",
    "        dataset = 'conus404-hourly-onprem-hw'\n",
    "        variables = ['T2', 'TD2', 'QVAPOR', 'U10', 'V10', 'PSFC', 'ACSWDNLSM']\n",
    "        print('using uncorrected data')\n",
    "    elif output_mode == 'ba':\n",
    "        variables = ['RAINRATE', 'T2D']\n",
    "        # bias-adjusted for precip and temp\n",
    "        dataset = 'conus404-hourly-ba-onprem-hw'\n",
    "        print('using bias-adjusted data')\n",
    "    else:\n",
    "        raise ValueError('output_mode not recognized')\n",
    "\n",
    "    ds = cat[dataset].to_dask()\n",
    "    # extract crs meta before continuing to modify ds\n",
    "    bounds_proj = projected_coords(row=None, _bounds=bounds, buffer=10000.)\n",
    "    ds = ds.sel(time=slice(f'{year}-{month}-01', f'{year}-{month}-{month_end}'))\n",
    "    ds = ds[variables]\n",
    "    if bounds_ is not None:\n",
    "        ds = ds.sel(y=slice(bounds_proj[1], bounds_proj[3]),\n",
    "                    x=slice(bounds_proj[0], bounds_proj[2]))\n",
    "    if output_mode == 'uncorrected':\n",
    "        station_list_ = station_list_.to_xarray()\n",
    "        # Add 'within_bounds' column (lat/lon)\n",
    "        station_list_['within_bounds'] = (\n",
    "            (station_list_.latitude >= ds.lat.min()) &\n",
    "            (station_list_.latitude <= ds.lat.max()) &\n",
    "            (station_list_.longitude >= ds.lon.min()) &\n",
    "            (station_list_.longitude <= ds.lon.max()))\n",
    "        ds.xoak.set_index(['lat', 'lon'], 'sklearn_geo_balltree')\n",
    "        ds = ds.xoak.sel(lat=station_list_.latitude, lon=station_list_.longitude, tolerance=4000)\n",
    "    else:\n",
    "        station_list_[['xs', 'ys']] = station_list_.apply(projected_coords, axis=1, result_type='expand')\n",
    "        station_list_ = station_list_.to_xarray()\n",
    "        # Add 'within_bounds' column (x/y)\n",
    "        station_list_['within_bounds'] = (\n",
    "            (station_list_.ys >= ds.y.min()) &\n",
    "            (station_list_.ys <= ds.y.max()) &\n",
    "            (station_list_.xs >= ds.x.min()) &\n",
    "            (station_list_.xs <= ds.x.max()))\n",
    "        try:\n",
    "            ds = ds.sel(y=station_list_.ys, x=station_list_.xs, method='nearest', tolerance=4000)\n",
    "        except KeyError as exc:\n",
    "            print(f\"KeyError: {exc}\")\n",
    "            print(bounds_proj)\n",
    "            print(bounds)\n",
    "            print(\"Problematic y values:\", np.array(station_list_.ys)[~np.isin(station_list_.ys, ds.y)])\n",
    "            print(ds)\n",
    "            return\n",
    "            \n",
    "    ds = xr.merge([station_list_, ds])\n",
    "    all_df = ds.to_dataframe()\n",
    "    print(f'to data frame {date_string}')\n",
    "\n",
    "    try:\n",
    "        ct = 0\n",
    "        for enum, fid in enumerate(fids, start=1):\n",
    "            print(f'{enum}: {ct} of {len(fids)}')\n",
    "            dst_dir = os.path.join(out_data, fid)\n",
    "            if not os.path.exists(dst_dir):\n",
    "                os.mkdir(dst_dir)\n",
    "            _file = os.path.join(dst_dir, f'{fid}_{date_string}.parquet')\n",
    "            if not os.path.exists(_file) or overwrite:\n",
    "                print(f'extract {fid} for {date_string}')\n",
    "                df_station = all_df.loc[slice(fid), slice(None)].copy()\n",
    "                df_station = df_station.groupby(df_station.index.get_level_values('time')).first()\n",
    "                df_station['dt'] = [i.strftime('%Y%m%d%H') for i in df_station.index]\n",
    "                df_station.to_parquet(_file, index=False)\n",
    "                ct += 1\n",
    "                print(f'wrote {_file}')\n",
    "        if ct % 1000 == 0.:\n",
    "            print(f'{ct} of {len(fids)} for {date_string}')\n",
    "    except Exception as exc:\n",
    "        print(f'{date_string}: {exc}')\n",
    "\n",
    "    del ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc0d5f689cdaaf85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T22:24:18.515088Z",
     "iopub.status.busy": "2024-11-28T22:24:18.514574Z",
     "iopub.status.idle": "2024-11-28T22:24:30.401879Z",
     "shell.execute_reply": "2024-11-28T22:24:30.401268Z",
     "shell.execute_reply.started": "2024-11-28T22:24:18.515068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask cluster started with dashboard at: http://127.0.0.1:8787/status\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dketchum/miniconda3/envs/hyt/lib/python3.10/site-packages/intake_xarray/base.py:21: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  'dims': dict(self._ds.dims),\n",
      "/home/dketchum/miniconda3/envs/hyt/lib/python3.10/site-packages/intake_xarray/base.py:21: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  'dims': dict(self._ds.dims),\n",
      "/home/dketchum/miniconda3/envs/hyt/lib/python3.10/site-packages/intake_xarray/base.py:21: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  'dims': dict(self._ds.dims),\n",
      "/home/dketchum/miniconda3/envs/hyt/lib/python3.10/site-packages/intake_xarray/base.py:21: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  'dims': dict(self._ds.dims),\n",
      "/home/dketchum/miniconda3/envs/hyt/lib/python3.10/site-packages/intake_xarray/base.py:21: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  'dims': dict(self._ds.dims),\n",
      "/home/dketchum/miniconda3/envs/hyt/lib/python3.10/site-packages/intake_xarray/base.py:21: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  'dims': dict(self._ds.dims),\n",
      "/home/dketchum/miniconda3/envs/hyt/lib/python3.10/site-packages/intake_xarray/base.py:21: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  'dims': dict(self._ds.dims),\n",
      "/home/dketchum/miniconda3/envs/hyt/lib/python3.10/site-packages/intake_xarray/base.py:21: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  'dims': dict(self._ds.dims),\n",
      "/home/dketchum/miniconda3/envs/hyt/lib/python3.10/site-packages/intake_xarray/base.py:21: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  'dims': dict(self._ds.dims),\n",
      "/home/dketchum/miniconda3/envs/hyt/lib/python3.10/site-packages/intake_xarray/base.py:21: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  'dims': dict(self._ds.dims),\n",
      "/home/dketchum/miniconda3/envs/hyt/lib/python3.10/site-packages/intake_xarray/base.py:21: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  'dims': dict(self._ds.dims),\n",
      "/home/dketchum/miniconda3/envs/hyt/lib/python3.10/site-packages/intake_xarray/base.py:21: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  'dims': dict(self._ds.dims),\n"
     ]
    }
   ],
   "source": [
    "output_target = 'ba'\n",
    "if mode == 'debug':\n",
    "    for date in dates:\n",
    "        get_month_met(station_list, date, out_data, overwrite, bounds, output_target)\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=workers) as executor:\n",
    "        futures = [\n",
    "            executor.submit(get_month_met, station_list, dt, out_data, overwrite, bounds, output_target)\n",
    "            for dt in dates]\n",
    "        concurrent.futures.wait(futures)\n",
    "\n",
    "elif mode == 'dask':\n",
    "    cluster = LocalCluster(n_workers=workers, memory_limit='32GB', threads_per_worker=1,\n",
    "                           silence_logs=logging.ERROR)\n",
    "    client = Client(cluster)\n",
    "    print(\"Dask cluster started with dashboard at:\", client.dashboard_link)\n",
    "    station_list = client.scatter(station_list)\n",
    "    tasks = [dask.delayed(get_month_met)(station_list, date, out_data, overwrite, bounds, output_target)\n",
    "             for date in\n",
    "             dates]\n",
    "    dask.compute(*tasks)\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119f20a3-eb82-4720-bca5-1294d01fd2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db494206-0d1b-4e4a-a498-a6d7b6b11294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyt",
   "language": "python",
   "name": "hyt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
