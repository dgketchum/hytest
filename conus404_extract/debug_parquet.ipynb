{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "initial_id",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T17:56:06.179831Z",
     "iopub.status.busy": "2024-12-05T17:56:06.179537Z",
     "iopub.status.idle": "2024-12-05T17:56:06.182495Z",
     "shell.execute_reply": "2024-12-05T17:56:06.182068Z",
     "shell.execute_reply.started": "2024-12-05T17:56:06.179812Z"
    }
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7878a77d059eb84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T17:56:06.483589Z",
     "iopub.status.busy": "2024-12-05T17:56:06.482971Z",
     "iopub.status.idle": "2024-12-05T17:56:06.487169Z",
     "shell.execute_reply": "2024-12-05T17:56:06.486757Z",
     "shell.execute_reply.started": "2024-12-05T17:56:06.483552Z"
    }
   },
   "outputs": [],
   "source": [
    "r = '/caldera/hovenweep/projects/usgs/water'\n",
    "d = os.path.join(r, 'wymtwsc', 'dketchum')\n",
    "\n",
    "if not os.path.isdir(d):\n",
    "    home = os.path.expanduser('~')\n",
    "    d = os.path.join(home, 'data', 'IrrigationGIS')\n",
    "\n",
    "c404 = os.path.join(d, 'conus404')\n",
    "dads = os.path.join(d, 'dads')\n",
    "ghcn = os.path.join(d, 'climate', 'ghcn')\n",
    "\n",
    "sites = os.path.join(dads, 'met', 'stations', 'madis_29OCT2024.csv')\n",
    "\n",
    "model_target = 'uncorrected'\n",
    "if model_target == 'ba':\n",
    "    csv_files = os.path.join(c404, 'station_data_ba')\n",
    "    p_files = os.path.join(c404, 'parquet_ba')\n",
    "else:\n",
    "    csv_files = os.path.join(c404, 'station_data')\n",
    "    p_files = os.path.join(c404, 'parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2205f6c4d297eac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T17:56:06.788306Z",
     "iopub.status.busy": "2024-12-05T17:56:06.787991Z",
     "iopub.status.idle": "2024-12-05T17:56:06.790718Z",
     "shell.execute_reply": "2024-12-05T17:56:06.790324Z",
     "shell.execute_reply.started": "2024-12-05T17:56:06.788292Z"
    }
   },
   "outputs": [],
   "source": [
    "stations = sites\n",
    "root = csv_files\n",
    "outdir = p_files\n",
    "workers = 1\n",
    "debug = True\n",
    "missing_file = None\n",
    "start_date='2000-01-01'\n",
    "end_date='2022-09-30'\n",
    "output_target = 'uncorrected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74f3b53980cb32b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T17:56:07.108459Z",
     "iopub.status.busy": "2024-12-05T17:56:07.108054Z",
     "iopub.status.idle": "2024-12-05T17:56:07.160689Z",
     "shell.execute_reply": "2024-12-05T17:56:07.160286Z",
     "shell.execute_reply.started": "2024-12-05T17:56:07.108423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53590 directories to check\n"
     ]
    }
   ],
   "source": [
    "start = pd.to_datetime(start_date)\n",
    "end = pd.to_datetime(end_date)\n",
    "expected_index = pd.date_range(start=start, end=end, freq='h')\n",
    "\n",
    "station_list = pd.read_csv(stations)\n",
    "if 'LAT' in station_list.columns:\n",
    "    station_list = station_list.rename(columns={'STAID': 'fid', 'LAT': 'latitude', 'LON': 'longitude'})\n",
    "w, s, e, n = (-125.0, 25.0, -67.0, 53.0)\n",
    "station_list = station_list[(station_list['latitude'] < n) & (station_list['latitude'] >= s)]\n",
    "station_list = station_list[(station_list['longitude'] < e) & (station_list['longitude'] >= w)]\n",
    "\n",
    "station_list = station_list.sample(frac=1)\n",
    "subdirs = station_list['fid'].to_list()\n",
    "\n",
    "print(f'{len(subdirs)} directories to check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0a07bc3-75ee-4144-8ab6-b263df63dd47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T17:57:53.395846Z",
     "iopub.status.busy": "2024-12-05T17:57:53.395557Z",
     "iopub.status.idle": "2024-12-05T17:57:53.401658Z",
     "shell.execute_reply": "2024-12-05T17:57:53.401231Z",
     "shell.execute_reply.started": "2024-12-05T17:57:53.395827Z"
    }
   },
   "outputs": [],
   "source": [
    "def conus404_parquet(root_, subdir_, expected_index_, outdir_):\n",
    "    subdir_path = os.path.join(root_, subdir_)\n",
    "    print(subdir_path)\n",
    "    out_file = os.path.join(outdir_, f'{subdir_}.parquet.gzip')\n",
    "\n",
    "    if os.path.isdir(subdir_path):\n",
    "        csv_files_ = [f for f in os.listdir(subdir_path) if f.endswith('.parquet')]\n",
    "        # if os.path.exists(out_file) and csv_files_:\n",
    "        #     shutil.rmtree(subdir_path)\n",
    "        #     print(f'{os.path.basename(out_file)} exists, removing {len(csv_files)} csv files')\n",
    "        #     return\n",
    "\n",
    "        dtimes = [f.split('_')[-1].replace('.csv', '') for f in csv_files_]\n",
    "        rm_files = csv_files_.copy()\n",
    "        required_years_ = sorted(list(set([i.year for i in expected_index_])))\n",
    "\n",
    "        if len(dtimes) < len(required_years_):\n",
    "            missing = [m for m in required_years_ if m not in dtimes]\n",
    "            if len(missing) > 0:\n",
    "                print(f'{subdir_} missing {len(missing)} months: {np.random.choice(missing, size=5, replace=False)}')\n",
    "                return\n",
    "\n",
    "        dfs = []\n",
    "        for file in csv_files_:\n",
    "            c = pd.read_parquet(os.path.join(subdir_path, file))\n",
    "            if file == csv_files_[0]:\n",
    "                print(c.head())\n",
    "            dfs.append(c)\n",
    "        df = pd.concat(dfs)\n",
    "        df = df.drop_duplicates(subset='dt', keep='first')\n",
    "        df = df.set_index('dt').sort_index()\n",
    "        missing = len(expected_index_) - df.shape[0]\n",
    "        if missing > 15:\n",
    "            print(f'{subdir_} is missing {missing} records')\n",
    "\n",
    "        df['dt'] = df.index\n",
    "        df.to_parquet(out_file, compression='gzip')\n",
    "        # shutil.rmtree(subdir_path)\n",
    "        now = datetime.strftime(datetime.now(), '%Y%m%d %H:%M')\n",
    "        print(f'wrote {outfile},{now}')\n",
    "        prq = \n",
    "\n",
    "    else:\n",
    "        if os.path.exists(out_file):\n",
    "            print(f'{os.path.basename(out_file)} exists, skipping')\n",
    "        else:\n",
    "            print(f'{subdir_} not found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c18acd2e838f671b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T17:57:53.749762Z",
     "iopub.status.busy": "2024-12-05T17:57:53.749345Z",
     "iopub.status.idle": "2024-12-05T17:58:01.362567Z",
     "shell.execute_reply": "2024-12-05T17:58:01.362131Z",
     "shell.execute_reply.started": "2024-12-05T17:57:53.749727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/caldera/hovenweep/projects/usgs/water/wymtwsc/dketchum/conus404/station_data/E4939\n",
      "    latitude  longitude   elev stype          T2         TD2    QVAPOR  \\\n",
      "0  42.062099 -93.698402  303.0   IEM  264.192200  259.629852  0.001376   \n",
      "1  42.062099 -93.698402  303.0   IEM  260.865295  256.627594  0.001073   \n",
      "2  42.062099 -93.698402  303.0   IEM  258.290771  253.972870  0.000857   \n",
      "3  42.062099 -93.698402  303.0   IEM  256.608063  252.200455  0.000736   \n",
      "4  42.062099 -93.698402  303.0   IEM  254.663788  251.362976  0.000696   \n",
      "\n",
      "        U10       V10          PSFC  ACSWDNLSM        lat        lon  \\\n",
      "0  5.738750  2.803222  96767.179688        0.0  42.058777 -93.717865   \n",
      "1  4.267025  1.518956  96892.562500        0.0  42.058777 -93.717865   \n",
      "2  3.572805  1.393518  96948.750000        0.0  42.058777 -93.717865   \n",
      "3  3.725136  1.291566  96964.593750        0.0  42.058777 -93.717865   \n",
      "4  2.706985  1.375903  97006.320312        0.0  42.058777 -93.717865   \n",
      "\n",
      "          x         y          dt  \n",
      "0  340000.0  332000.0  2011010100  \n",
      "1  340000.0  332000.0  2011010101  \n",
      "2  340000.0  332000.0  2011010102  \n",
      "3  340000.0  332000.0  2011010103  \n",
      "4  340000.0  332000.0  2011010104  \n",
      "wrote E4939,20241205 11:58\n"
     ]
    }
   ],
   "source": [
    "if debug:\n",
    "    for subdir in ['E4939']:\n",
    "        conus404_parquet(root, subdir, expected_index, outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6385f1-084f-490c-990d-be5db73f490e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyt",
   "language": "python",
   "name": "hyt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
