{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Chunking Larger Datasets \n",
    "\n",
    "This notebook extends ideas covered in the [basic workflow](./ReChunkingData.ipynb).  This \n",
    "notebook will perfrom the same operations, but will work on the **much** larger dataset, and \n",
    "involve some parallelization using the dask scheduler. \n",
    "\n",
    ":::{Warning}\n",
    "\n",
    "You should run this **only** on a cloud compute node -- on ESIP Nebari, for example. We \n",
    "will be reading and writing **enormous** amounts of data to S3 buckets. To do that over a \n",
    "typical network connection will saturate your bandwidth and take days to complete.\n",
    "\n",
    ":::\n",
    "\n",
    "## System Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, force=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plumb Data Source\n",
    "We're going to look at a particular dataset from the National Water Model Reanalysis Version 2.1. \n",
    "The dataset is part of the AWS Open Data Program, and is included in the HyTEST data catalog.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "application/yaml": "nwm21-streamflow-cloud:\n  args:\n    consolidated: true\n    storage_options:\n      anon: true\n    urlpath: s3://noaa-nwm-retrospective-2-1-zarr-pds/chrtout.zarr\n  description: National Water Model 2.1 CHRTOUT on AWS\n  driver: intake_xarray.xzarr.ZarrSource\n  metadata:\n    catalog_dir: https://raw.githubusercontent.com/hytest-org/hytest/main/dataset_catalog\n",
      "text/plain": [
       "nwm21-streamflow-cloud:\n",
       "  args:\n",
       "    consolidated: true\n",
       "    storage_options:\n",
       "      anon: true\n",
       "    urlpath: s3://noaa-nwm-retrospective-2-1-zarr-pds/chrtout.zarr\n",
       "  description: National Water Model 2.1 CHRTOUT on AWS\n",
       "  driver: intake_xarray.xzarr.ZarrSource\n",
       "  metadata:\n",
       "    catalog_dir: https://raw.githubusercontent.com/hytest-org/hytest/main/dataset_catalog\n"
      ]
     },
     "metadata": {
      "application/json": {
       "root": "nwm21-streamflow-cloud"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import intake\n",
    "url = 'https://raw.githubusercontent.com/hytest-org/hytest/main/dataset_catalog/hytest_intake_catalog.yml'\n",
    "cat = intake.open_catalog(url)\n",
    "cat['nwm21-streamflow-cloud']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the zarr data\n",
    "We'll take advantage of the `intake` mechanism and load the data \n",
    "directly.  We'll need to set up our AWS credentials first, since\n",
    "this data is stored on an S3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import configparser\n",
    "awsconfig = configparser.ConfigParser()\n",
    "awsconfig.read(\n",
    "    os.path.expanduser('~/.aws/credentials') # default location... if yours is elsewhere, change this.\n",
    ")\n",
    "_profile_nm  = 'osn-renci'\n",
    "_endpoint = 'https://renc.osn.xsede.org'\n",
    "# Set environment vars based on parsed awsconfig\n",
    "os.environ['AWS_PROFILE'] = _profile_nm\n",
    "os.environ['AWS_ACCESS_KEY_ID']     = awsconfig[_profile_nm]['aws_access_key_id']    \n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = awsconfig[_profile_nm]['aws_secret_access_key']    \n",
    "## Your profile may require that you specify an endpoint by which  you access S3 object storage\n",
    "os.environ['AWS_S3_ENDPOINT'] = _endpoint\n",
    "try: \n",
    "    del os.environ['AWS_PROFILE']\n",
    "except KeyError:\n",
    "    pass\n",
    "#ds = cat['nwm21-streamflow-cloud'].to_dask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "# f = fsspec.filesystem(\"s3\", anon=False)\n",
    "# f.ls(\"s3://esip-qhub/usgs/hytest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spin up Dask Cluster\n",
    "Our rechunking operation will be able to work in parallel. To do that, we will\n",
    "spin up a `dask` cluster on the cloud hardware to schedule the various workers.\n",
    "Note that this cluster must be configured with a specific user **profile** with \n",
    "permissions to write to our eventual output location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'cluster' object can be used to adjust cluster behavior.  i.e. 'cluster.adapt(minimum=10)'\n",
      "The 'client' object can be used to directly interact with the cluster.  i.e. 'client.submit(func)' \n",
      "The link to view the client dashboard is:\n",
      ">  https://nebari.esipfed.org/gateway/clusters/dev.0338ebba9cbe44518ae21a4633525692/status\n"
     ]
    }
   ],
   "source": [
    "# %run ../environment_set_up/Start_Dask_Cluster_Nebari.ipynb\n",
    "import os\n",
    "import logging\n",
    "\n",
    "try:\n",
    "    from dask_gateway import Gateway\n",
    "except ImportError:\n",
    "    logging.error(\"Unable to import Dask Gateway.  Are you running in a cloud compute environment?\\n\")\n",
    "    raise\n",
    "os.environ['DASK_DISTRIBUTED__SCHEDULER__WORKER_SATURATION'] = \"1.0\"\n",
    "\n",
    "gateway = Gateway()\n",
    "_options = gateway.cluster_options()\n",
    "_options.conda_environment='users/users-pangeo'  ##<< this is the conda environment we use on nebari.\n",
    "_options.profile = 'Medium Worker'\n",
    "_env_to_add={}\n",
    "aws_env_vars=['AWS_ACCESS_KEY_ID',\n",
    "              'AWS_SECRET_ACCESS_KEY',\n",
    "              'AWS_SESSION_TOKEN',\n",
    "              'AWS_DEFAULT_REGION',\n",
    "              'AWS_S3_ENDPOINT', \n",
    "              'DASK_DISTRIBUTED__SCHEDULER__WORKER_SATURATION']\n",
    "for _e in aws_env_vars:\n",
    "    if _e in os.environ:\n",
    "        _env_to_add[_e] = os.environ[_e]\n",
    "_options.environment_vars = _env_to_add    \n",
    "cluster = gateway.new_cluster(_options)          ##<< create cluster via the dask gateway\n",
    "cluster.adapt(minimum=2, maximum=30)             ##<< Sets scaling parameters. \n",
    "\n",
    "client = cluster.get_client()\n",
    "\n",
    "print(\"The 'cluster' object can be used to adjust cluster behavior.  i.e. 'cluster.adapt(minimum=10)'\")\n",
    "print(\"The 'client' object can be used to directly interact with the cluster.  i.e. 'client.submit(func)' \")\n",
    "print(f\"The link to view the client dashboard is:\\n>  {client.dashboard_link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dask\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray.slicing.split_large_chunks\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}):\n\u001b[0;32m----> 3\u001b[0m     smplData \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39mwhere(ds\u001b[38;5;241m.\u001b[39mgage_id \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mrjust(\u001b[38;5;241m15\u001b[39m)\u001b[38;5;241m.\u001b[39mencode(), drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# subset to only those features with a valid gage_id\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     smplData\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrs\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# Not needed/wanted for this analysis\u001b[39;00m\n\u001b[1;32m      5\u001b[0m smplData\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
    "    smplData = ds.where(ds.gage_id != ''.rjust(15).encode(), drop=True) # subset to only those features with a valid gage_id\n",
    "    smplData.drop('crs') # Not needed/wanted for this analysis\n",
    "smplData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Chunk Plan\n",
    "We will configure a new chunking plan which will favor time-series analysis. \n",
    "Using the dimensions of the data: \n",
    "* 367439 time steps\n",
    "* 7994 feature IDs\n",
    "\n",
    "We can write the new plan as: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The new chunking plan:\n",
    "chunk_plan = {\n",
    "    'streamflow': {'time': 367439, 'feature_id': 1}, # all time records in one chunk for each feature_id\n",
    "    'velocity': {'time': 367439, 'feature_id': 1},\n",
    "    'elevation': (7994,),\n",
    "    'gage_id': (7994,),\n",
    "    'latitude': (7994,),\n",
    "    'longitude': (7994,),    \n",
    "    'order': (7994,),    \n",
    "    'time': (367439,), # all time coordinates in one chunk\n",
    "    'feature_id': (7994,) # all feature_id coordinates in one chunk\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'DASK_DISTRIBUTED__SCHEDULER__WORKER_SATURATION'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDASK_DISTRIBUTED__SCHEDULER__WORKER_SATURATION\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/home/conda/gzt5142/1dfd8fe1b86da1a6392d58bb46e0fd6aca50eee9f2d520713247871ecc98dc35-20230307-170618-318228-114-pangeo-jbook/lib/python3.9/os.py:695\u001b[0m, in \u001b[0;36m_Environ.__delitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[encodedkey]\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;66;03m# raise KeyError with the original key value\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'DASK_DISTRIBUTED__SCHEDULER__WORKER_SATURATION'"
     ]
    }
   ],
   "source": [
    "del os.environ['DASK_DISTRIBUTED__SCHEDULER__WORKER_SATURATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually reset the chunking metadata in prep for re-chunking\n",
    "#smplData = smplData.chunk(chunks={'feature_id':1, 'time': 367439})\n",
    "for x in smplData.variables:\n",
    "    smplData[x].encoding['chunks'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up output location\n",
    "\n",
    "With this plan, we can ask `rechunker` to re-write the data using the prescribed chunking pattern.\n",
    "\n",
    "Unlike with the smaller dataset, we need to write this very large dataset to an object store in the datacenter: an S3 'bucket'.  So we need to set that up so that `rechunker` will have a suitable place to write data. This new data will be a complete copy of the original, just re-organized a bit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AWS_DEFAULT_REGION']='us-west-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:aiobotocore.credentials:Found credentials in environment variables.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rsignellbucket2/testing/02_kerchunk.ipynb',\n",
       " 'rsignellbucket2/testing/ATL08_20181014084920_02400109_003_01.h5',\n",
       " 'rsignellbucket2/testing/cluster_conf.py',\n",
       " 'rsignellbucket2/testing/cog',\n",
       " 'rsignellbucket2/testing/combine_files_tpBiasCorr.csh',\n",
       " 'rsignellbucket2/testing/foo.json',\n",
       " 'rsignellbucket2/testing/gzt5142',\n",
       " 'rsignellbucket2/testing/ortho_2021_10_7_sageLot_noalpha_clip_cog.tif',\n",
       " 'rsignellbucket2/testing/time']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from getpass import getuser\n",
    "import fsspec\n",
    "uname=getuser()\n",
    "\n",
    "fsw = fsspec.filesystem(\n",
    "    's3', \n",
    "    anon=False, \n",
    "    default_fill_cache=False, \n",
    "    skip_instance_cache=True, \n",
    "    client_kwargs={'endpoint_url': os.environ['AWS_S3_ENDPOINT'], }\n",
    ")\n",
    "#workspace= \"s3://esip-qhub/usgs/hytest\"\n",
    "os.environ['AWS_PROFILE'] = _profile_nm\n",
    "\n",
    "workspace = 's3://rsignellbucket2/'\n",
    "testDir = workspace + \"testing/\"\n",
    "myDir = testDir + f'{uname}/'\n",
    "fsw.mkdir(testDir)\n",
    "fsw.ls(testDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in ['rechunked.zarr', 'staging.zarr', 'writetest.csv']:\n",
    "    if fsw.exists(myDir + fn):\n",
    "        fsw.rm(myDir + fn, recursive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "#staging = fsw.get_mapper(myDir + 'staging.zarr')\n",
    "#del os.environ['AWS_PROFILE']\n",
    "os.environ['AWS_PROFILE'] = _profile_nm\n",
    "\n",
    "staging = zarr.storage.FSStore(myDir + 'staging.zarr', mode=\"w\")\n",
    "\n",
    "outfile = fsw.get_mapper(myDir + 'rechunked.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/home/conda/gzt5142/1dfd8fe1b86da1a6392d58bb46e0fd6aca50eee9f2d520713247871ecc98dc35-20230307-170618-318228-114-pangeo-jbook/lib/python3.9/site-packages/s3fs/core.py:112\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[0;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m S3_RETRYABLE_ERRORS \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/home/conda/gzt5142/1dfd8fe1b86da1a6392d58bb46e0fd6aca50eee9f2d520713247871ecc98dc35-20230307-170618-318228-114-pangeo-jbook/lib/python3.9/site-packages/aiobotocore/client.py:358\u001b[0m, in \u001b[0;36mAioBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    357\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (403) when calling the HeadObject operation: Forbidden",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mzarr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstaging\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/conda/gzt5142/1dfd8fe1b86da1a6392d58bb46e0fd6aca50eee9f2d520713247871ecc98dc35-20230307-170618-318228-114-pangeo-jbook/lib/python3.9/site-packages/zarr/hierarchy.py:1350\u001b[0m, in \u001b[0;36mgroup\u001b[0;34m(store, overwrite, chunk_store, cache_attrs, synchronizer, path, zarr_version)\u001b[0m\n\u001b[1;32m   1348\u001b[0m requires_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m zarr_version \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1350\u001b[0m     requires_init \u001b[38;5;241m=\u001b[39m overwrite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontains_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m zarr_version \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m   1352\u001b[0m     requires_init \u001b[38;5;241m=\u001b[39m overwrite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m contains_group(store, path)\n",
      "File \u001b[0;32m/home/conda/gzt5142/1dfd8fe1b86da1a6392d58bb46e0fd6aca50eee9f2d520713247871ecc98dc35-20230307-170618-318228-114-pangeo-jbook/lib/python3.9/site-packages/zarr/storage.py:117\u001b[0m, in \u001b[0;36mcontains_group\u001b[0;34m(store, path, explicit_only)\u001b[0m\n\u001b[1;32m    115\u001b[0m store_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(store, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_store_version\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m store_version \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m explicit_only:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m store:\n",
      "File \u001b[0;32m/home/conda/gzt5142/1dfd8fe1b86da1a6392d58bb46e0fd6aca50eee9f2d520713247871ecc98dc35-20230307-170618-318228-114-pangeo-jbook/lib/python3.9/site-packages/zarr/storage.py:1430\u001b[0m, in \u001b[0;36mFSStore.__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__contains__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   1429\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_key(key)\n\u001b[0;32m-> 1430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\n",
      "File \u001b[0;32m/home/conda/gzt5142/1dfd8fe1b86da1a6392d58bb46e0fd6aca50eee9f2d520713247871ecc98dc35-20230307-170618-318228-114-pangeo-jbook/lib/python3.9/site-packages/fsspec/mapping.py:181\u001b[0m, in \u001b[0;36mFSMap.__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Does key exist in mapping?\"\"\"\u001b[39;00m\n\u001b[1;32m    180\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key_to_str(key)\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39misfile(path)\n",
      "File \u001b[0;32m/home/conda/gzt5142/1dfd8fe1b86da1a6392d58bb46e0fd6aca50eee9f2d520713247871ecc98dc35-20230307-170618-318228-114-pangeo-jbook/lib/python3.9/site-packages/fsspec/asyn.py:114\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m obj \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/conda/gzt5142/1dfd8fe1b86da1a6392d58bb46e0fd6aca50eee9f2d520713247871ecc98dc35-20230307-170618-318228-114-pangeo-jbook/lib/python3.9/site-packages/fsspec/asyn.py:99\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FSTimeoutError \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreturn_result\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m return_result\n",
      "File \u001b[0;32m/home/conda/gzt5142/1dfd8fe1b86da1a6392d58bb46e0fd6aca50eee9f2d520713247871ecc98dc35-20230307-170618-318228-114-pangeo-jbook/lib/python3.9/site-packages/fsspec/asyn.py:54\u001b[0m, in \u001b[0;36m_runner\u001b[0;34m(event, coro, result, timeout)\u001b[0m\n\u001b[1;32m     52\u001b[0m     coro \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mwait_for(coro, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m     56\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m ex\n",
      "File \u001b[0;32m/home/conda/gzt5142/1dfd8fe1b86da1a6392d58bb46e0fd6aca50eee9f2d520713247871ecc98dc35-20230307-170618-318228-114-pangeo-jbook/lib/python3.9/site-packages/s3fs/core.py:946\u001b[0m, in \u001b[0;36mS3FileSystem._exists\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 946\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info(path, bucket, key, version_id\u001b[38;5;241m=\u001b[39mversion_id)\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "File \u001b[0;32m/home/conda/gzt5142/1dfd8fe1b86da1a6392d58bb46e0fd6aca50eee9f2d520713247871ecc98dc35-20230307-170618-318228-114-pangeo-jbook/lib/python3.9/site-packages/s3fs/core.py:1210\u001b[0m, in \u001b[0;36mS3FileSystem._info\u001b[0;34m(self, path, bucket, key, refresh, version_id)\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key:\n\u001b[1;32m   1209\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1210\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_s3(\n\u001b[1;32m   1211\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead_object\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1212\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[1;32m   1213\u001b[0m             Bucket\u001b[38;5;241m=\u001b[39mbucket,\n\u001b[1;32m   1214\u001b[0m             Key\u001b[38;5;241m=\u001b[39mkey,\n\u001b[1;32m   1215\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mversion_id_kw(version_id),\n\u001b[1;32m   1216\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreq_kw,\n\u001b[1;32m   1217\u001b[0m         )\n\u001b[1;32m   1218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m   1219\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mETag\u001b[39m\u001b[38;5;124m\"\u001b[39m: out\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mETag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1220\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLastModified\u001b[39m\u001b[38;5;124m\"\u001b[39m: out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLastModified\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1226\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContentType\u001b[39m\u001b[38;5;124m\"\u001b[39m: out\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContentType\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1227\u001b[0m         }\n\u001b[1;32m   1228\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "File \u001b[0;32m/home/conda/gzt5142/1dfd8fe1b86da1a6392d58bb46e0fd6aca50eee9f2d520713247871ecc98dc35-20230307-170618-318228-114-pangeo-jbook/lib/python3.9/site-packages/s3fs/core.py:339\u001b[0m, in \u001b[0;36mS3FileSystem._call_s3\u001b[0;34m(self, method, *akwarglist, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCALL: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, akwarglist, kw2)\n\u001b[1;32m    338\u001b[0m additional_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_s3_method_kwargs(method, \u001b[38;5;241m*\u001b[39makwarglist, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _error_wrapper(\n\u001b[1;32m    340\u001b[0m     method, kwargs\u001b[38;5;241m=\u001b[39madditional_kwargs, retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries\n\u001b[1;32m    341\u001b[0m )\n",
      "File \u001b[0;32m/home/conda/gzt5142/1dfd8fe1b86da1a6392d58bb46e0fd6aca50eee9f2d520713247871ecc98dc35-20230307-170618-318228-114-pangeo-jbook/lib/python3.9/site-packages/s3fs/core.py:139\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[0;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[1;32m    137\u001b[0m         err \u001b[38;5;241m=\u001b[39m e\n\u001b[1;32m    138\u001b[0m err \u001b[38;5;241m=\u001b[39m translate_boto_error(err)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "\u001b[0;31mPermissionError\u001b[0m: Forbidden"
     ]
    }
   ],
   "source": [
    "zarr.group(staging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready to rechunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadOnlyError",
     "evalue": "object is read-only",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReadOnlyError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrechunker\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m## Recall that merely invoking rechunker does not do any work... just sorts out \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m## the rechunking plan and writes metadata.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrechunker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrechunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msmplData\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_plan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2GB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemp_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstaging\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/conda/gzt5142/1dfd8fe1b86da1a6392d58bb46e0fd6aca50eee9f2d520713247871ecc98dc35-20230307-170618-318228-114-pangeo-jbook/lib/python3.9/site-packages/rechunker/api.py:302\u001b[0m, in \u001b[0;36mrechunk\u001b[0;34m(source, target_chunks, max_mem, target_store, target_options, temp_store, temp_options, executor)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(executor, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    300\u001b[0m     executor \u001b[38;5;241m=\u001b[39m _get_executor(executor)\n\u001b[0;32m--> 302\u001b[0m copy_spec, intermediate, target \u001b[38;5;241m=\u001b[39m \u001b[43m_setup_rechunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_chunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_mem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_mem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemp_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemp_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemp_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemp_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m plan \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mprepare_plan(copy_spec)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Rechunked(executor, plan, source, intermediate, target)\n",
      "File \u001b[0;32m/home/conda/gzt5142/1dfd8fe1b86da1a6392d58bb46e0fd6aca50eee9f2d520713247871ecc98dc35-20230307-170618-318228-114-pangeo-jbook/lib/python3.9/site-packages/rechunker/api.py:376\u001b[0m, in \u001b[0;36m_setup_rechunk\u001b[0;34m(source, target_chunks, max_mem, target_store, target_options, temp_store, temp_options)\u001b[0m\n\u001b[1;32m    373\u001b[0m attrs \u001b[38;5;241m=\u001b[39m _encode_zarr_attributes(attrs)\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m temp_store \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     temp_group \u001b[38;5;241m=\u001b[39m \u001b[43mzarr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_store\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     temp_group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/conda/gzt5142/1dfd8fe1b86da1a6392d58bb46e0fd6aca50eee9f2d520713247871ecc98dc35-20230307-170618-318228-114-pangeo-jbook/lib/python3.9/site-packages/zarr/hierarchy.py:1355\u001b[0m, in \u001b[0;36mgroup\u001b[0;34m(store, overwrite, chunk_store, cache_attrs, synchronizer, path, zarr_version)\u001b[0m\n\u001b[1;32m   1352\u001b[0m     requires_init \u001b[38;5;241m=\u001b[39m overwrite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m contains_group(store, path)\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m requires_init:\n\u001b[0;32m-> 1355\u001b[0m     \u001b[43minit_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[43m               \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Group(store, read_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, chunk_store\u001b[38;5;241m=\u001b[39mchunk_store,\n\u001b[1;32m   1359\u001b[0m              cache_attrs\u001b[38;5;241m=\u001b[39mcache_attrs, synchronizer\u001b[38;5;241m=\u001b[39msynchronizer, path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[1;32m   1360\u001b[0m              zarr_version\u001b[38;5;241m=\u001b[39mzarr_version)\n",
      "File \u001b[0;32m/home/conda/gzt5142/1dfd8fe1b86da1a6392d58bb46e0fd6aca50eee9f2d520713247871ecc98dc35-20230307-170618-318228-114-pangeo-jbook/lib/python3.9/site-packages/zarr/storage.py:643\u001b[0m, in \u001b[0;36minit_group\u001b[0;34m(store, overwrite, path, chunk_store)\u001b[0m\n\u001b[1;32m    640\u001b[0m     store[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzarr.json\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m store\u001b[38;5;241m.\u001b[39m_metadata_class\u001b[38;5;241m.\u001b[39mencode_hierarchy_metadata(\u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;66;03m# initialise metadata\u001b[39;00m\n\u001b[0;32m--> 643\u001b[0m \u001b[43m_init_group_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mchunk_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_store\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m store_version \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;66;03m# TODO: Should initializing a v3 group also create a corresponding\u001b[39;00m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;66;03m#       empty folder under data/root/? I think probably not until there\u001b[39;00m\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;66;03m#       is actual data written there.\u001b[39;00m\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/home/conda/gzt5142/1dfd8fe1b86da1a6392d58bb46e0fd6aca50eee9f2d520713247871ecc98dc35-20230307-170618-318228-114-pangeo-jbook/lib/python3.9/site-packages/zarr/storage.py:706\u001b[0m, in \u001b[0;36m_init_group_metadata\u001b[0;34m(store, overwrite, path, chunk_store)\u001b[0m\n\u001b[1;32m    704\u001b[0m key \u001b[38;5;241m=\u001b[39m _prefix_to_group_key(store, _path_to_prefix(path))\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(store, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_metadata_class\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 706\u001b[0m     \u001b[43mstore\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m store\u001b[38;5;241m.\u001b[39m_metadata_class\u001b[38;5;241m.\u001b[39mencode_group_metadata(meta)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    708\u001b[0m     store[key] \u001b[38;5;241m=\u001b[39m encode_group_metadata(meta)\n",
      "File \u001b[0;32m/home/conda/gzt5142/1dfd8fe1b86da1a6392d58bb46e0fd6aca50eee9f2d520713247871ecc98dc35-20230307-170618-318228-114-pangeo-jbook/lib/python3.9/site-packages/zarr/storage.py:1398\u001b[0m, in \u001b[0;36mFSStore.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value):\n\u001b[1;32m   1397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1398\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ReadOnlyError()\n\u001b[1;32m   1399\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_key(key)\n\u001b[1;32m   1400\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdir_path(key)\n",
      "\u001b[0;31mReadOnlyError\u001b[0m: object is read-only"
     ]
    }
   ],
   "source": [
    "import rechunker\n",
    "## Recall that merely invoking rechunker does not do any work... just sorts out \n",
    "## the rechunking plan and writes metadata.\n",
    "result = rechunker.rechunk(\n",
    "    smplData,\n",
    "    chunk_plan,\n",
    "    \"2GB\",\n",
    "    outfile, \n",
    "    temp_store=staging, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'tx0000038f5da0f45a7b4b4-00640b5584-a9e24-default',\n",
       "  'HostId': '',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-length': '0',\n",
       "   'etag': '\"d41d8cd98f00b204e9800998ecf8427e\"',\n",
       "   'accept-ranges': 'bytes',\n",
       "   'x-amz-request-id': 'tx0000038f5da0f45a7b4b4-00640b5584-a9e24-default',\n",
       "   'date': 'Fri, 10 Mar 2023 16:06:29 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"d41d8cd98f00b204e9800998ecf8427e\"'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=myDir + \"write_test.txt\"\n",
    "fsw.touch(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rsignellbucket2/testing/gzt5142/write_test.txt']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsw.ls(myDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "group() got an unexpected keyword argument 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzarr\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mzarr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstaging\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: group() got an unexpected keyword argument 'mode'"
     ]
    }
   ],
   "source": [
    "import zarr\n",
    "zarr.group(store=staging, overwrite=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fsspec.mapping.FSMap at 0x7f9b27fd0100>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fsspec.mapping.FSMap"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.distributed import progress, performance_report\n",
    "\n",
    "with performance_report(filename=\"dask-report.html\"):\n",
    "    r = result.execute(retries=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "_ = zarr.consolidate_metadata(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Let's read in the resulting re-chunked dataset to see how it looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: '<fsspec.mapping.FSMap object at 0x7f151aa90430>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchKey\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/s3fs/core.py:112\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[0;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m S3_RETRYABLE_ERRORS \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/aiobotocore/client.py:358\u001b[0m, in \u001b[0;36mAioBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    357\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNoSuchKey\u001b[0m: An error occurred (NoSuchKey) when calling the GetObject operation: Unknown",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/fsspec/mapping.py:143\u001b[0m, in \u001b[0;36mFSMap.__getitem__\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing_exceptions:\n",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/fsspec/asyn.py:115\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m obj \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/fsspec/asyn.py:100\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/fsspec/asyn.py:55\u001b[0m, in \u001b[0;36m_runner\u001b[0;34m(event, coro, result, timeout)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/fsspec/asyn.py:414\u001b[0m, in \u001b[0;36mAsyncFileSystem._cat\u001b[0;34m(self, path, recursive, on_error, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ex:\n\u001b[0;32m--> 414\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28mlen\u001b[39m(paths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m paths[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strip_protocol(path)\n\u001b[1;32m    419\u001b[0m ):\n",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/asyncio/tasks.py:442\u001b[0m, in \u001b[0;36mwait_for\u001b[0;34m(fut, timeout, loop)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/s3fs/core.py:1013\u001b[0m, in \u001b[0;36mS3FileSystem._cat_file\u001b[0;34m(self, path, version_id, start, end)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         resp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBody\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _error_wrapper(_call_and_read, retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries)\n",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/s3fs/core.py:139\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[0;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[1;32m    138\u001b[0m err \u001b[38;5;241m=\u001b[39m translate_boto_error(err)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/s3fs/core.py:112\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[0;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m S3_RETRYABLE_ERRORS \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/s3fs/core.py:1000\u001b[0m, in \u001b[0;36mS3FileSystem._cat_file.<locals>._call_and_read\u001b[0;34m()\u001b[0m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_and_read\u001b[39m():\n\u001b[0;32m-> 1000\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_s3(\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_object\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1002\u001b[0m         Bucket\u001b[38;5;241m=\u001b[39mbucket,\n\u001b[1;32m   1003\u001b[0m         Key\u001b[38;5;241m=\u001b[39mkey,\n\u001b[1;32m   1004\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mversion_id_kw(version_id \u001b[38;5;129;01mor\u001b[39;00m vers),\n\u001b[1;32m   1005\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhead,\n\u001b[1;32m   1006\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreq_kw,\n\u001b[1;32m   1007\u001b[0m     )\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/s3fs/core.py:339\u001b[0m, in \u001b[0;36mS3FileSystem._call_s3\u001b[0;34m(self, method, *akwarglist, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m additional_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_s3_method_kwargs(method, \u001b[38;5;241m*\u001b[39makwarglist, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _error_wrapper(\n\u001b[1;32m    340\u001b[0m     method, kwargs\u001b[38;5;241m=\u001b[39madditional_kwargs, retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries\n\u001b[1;32m    341\u001b[0m )\n",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/s3fs/core.py:139\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[0;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[1;32m    138\u001b[0m err \u001b[38;5;241m=\u001b[39m translate_boto_error(err)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: An error occurred (NoSuchKey) when calling the GetObject operation: Unknown",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/zarr/storage.py:1386\u001b[0m, in \u001b[0;36mFSStore.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/fsspec/mapping.py:147\u001b[0m, in \u001b[0;36mFSMap.__getitem__\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyError\u001b[0m: '.zmetadata'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/xarray/backends/zarr.py:405\u001b[0m, in \u001b[0;36mZarrStore.open_group\u001b[0;34m(cls, store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, append_dim, write_region, safe_chunks, stacklevel, zarr_version)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     zarr_group \u001b[38;5;241m=\u001b[39m \u001b[43mzarr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_consolidated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/zarr/convenience.py:1299\u001b[0m, in \u001b[0;36mopen_consolidated\u001b[0;34m(store, metadata_key, mode, **kwargs)\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[38;5;66;03m# setup metadata store\u001b[39;00m\n\u001b[0;32m-> 1299\u001b[0m meta_store \u001b[38;5;241m=\u001b[39m \u001b[43mConsolidatedStoreClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;66;03m# pass through\u001b[39;00m\n",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/zarr/storage.py:2873\u001b[0m, in \u001b[0;36mConsolidatedMetadataStore.__init__\u001b[0;34m(self, store, metadata_key)\u001b[0m\n\u001b[1;32m   2872\u001b[0m \u001b[38;5;66;03m# retrieve consolidated metadata\u001b[39;00m\n\u001b[0;32m-> 2873\u001b[0m meta \u001b[38;5;241m=\u001b[39m json_loads(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetadata_key\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m   2875\u001b[0m \u001b[38;5;66;03m# check format of consolidated metadata\u001b[39;00m\n",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/zarr/storage.py:1388\u001b[0m, in \u001b[0;36mFSStore.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1388\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: '.zmetadata'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mGroupNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/xarray/backends/zarr.py:408\u001b[0m, in \u001b[0;36mZarrStore.open_group\u001b[0;34m(cls, store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, append_dim, write_region, safe_chunks, stacklevel, zarr_version)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m     zarr_group \u001b[38;5;241m=\u001b[39m \u001b[43mzarr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to open Zarr store with consolidated metadata, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut successfully read with non-consolidated metadata. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    423\u001b[0m     )\n",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/zarr/hierarchy.py:1443\u001b[0m, in \u001b[0;36mopen_group\u001b[0;34m(store, mode, cache_attrs, synchronizer, path, chunk_store, storage_options, zarr_version, meta_array)\u001b[0m\n\u001b[1;32m   1442\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m ContainsArrayError(path)\n\u001b[0;32m-> 1443\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m GroupNotFoundError(path)\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mGroupNotFoundError\u001b[0m: group not found at path ''",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m reChunkedData \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_zarr\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m reChunkedData\n",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/xarray/backends/zarr.py:829\u001b[0m, in \u001b[0;36mopen_zarr\u001b[0;34m(store, group, synchronizer, chunks, decode_cf, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, consolidated, overwrite_encoded_chunks, chunk_store, storage_options, decode_timedelta, use_cftime, zarr_version, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopen_zarr() got unexpected keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(kwargs\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    817\u001b[0m     )\n\u001b[1;32m    819\u001b[0m backend_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msynchronizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: synchronizer,\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsolidated\u001b[39m\u001b[38;5;124m\"\u001b[39m: consolidated,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzarr_version\u001b[39m\u001b[38;5;124m\"\u001b[39m: zarr_version,\n\u001b[1;32m    827\u001b[0m }\n\u001b[0;32m--> 829\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_cf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_cf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_and_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_and_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_times\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcat_characters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcat_characters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzarr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_timedelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_timedelta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cftime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cftime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mzarr_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzarr_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/xarray/backends/api.py:526\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    515\u001b[0m     decode_cf,\n\u001b[1;32m    516\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    523\u001b[0m )\n\u001b[1;32m    525\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 526\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    533\u001b[0m     backend_ds,\n\u001b[1;32m    534\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    543\u001b[0m )\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/xarray/backends/zarr.py:891\u001b[0m, in \u001b[0;36mZarrBackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, synchronizer, consolidated, chunk_store, storage_options, stacklevel, zarr_version)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    873\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    888\u001b[0m     zarr_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    889\u001b[0m ):\n\u001b[1;32m    890\u001b[0m     filename_or_obj \u001b[38;5;241m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[0;32m--> 891\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43mZarrStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynchronizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsolidated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsolidate_on_close\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstacklevel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzarr_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzarr_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    904\u001b[0m     store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[0;32m/home/conda/gzt5142/267fcae1bebb4612046db0273f49e240db8d395a432a7eb17d4a4dc8415a560e-20230306-135407-716724-111-pangeo-jbook/lib/python3.9/site-packages/xarray/backends/zarr.py:425\u001b[0m, in \u001b[0;36mZarrStore.open_group\u001b[0;34m(cls, store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, append_dim, write_region, safe_chunks, stacklevel, zarr_version)\u001b[0m\n\u001b[1;32m    409\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    410\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to open Zarr store with consolidated metadata, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut successfully read with non-consolidated metadata. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    423\u001b[0m             )\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m zarr\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mGroupNotFoundError:\n\u001b[0;32m--> 425\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m consolidated:\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;66;03m# TODO: an option to pass the metadata_key keyword\u001b[39;00m\n\u001b[1;32m    428\u001b[0m     zarr_group \u001b[38;5;241m=\u001b[39m zarr\u001b[38;5;241m.\u001b[39mopen_consolidated(store, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopen_kwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: '<fsspec.mapping.FSMap object at 0x7f151aa90430>'"
     ]
    }
   ],
   "source": [
    "reChunkedData = xr.open_zarr(outfile)\n",
    "reChunkedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Before:\n",
    "sampleData['streamflow'].sel(feature_id=1343034)\n",
    "# Note: three chunks needed to service a single feature_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## After:\n",
    "reChunkedData['streamflow'].sel(feature_id=1343034) \n",
    "# All data for the specified feature_id is in a single chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def myAWS_Credentials():\n",
    "    \"\"\"Test function to return AWS credential information.\"\"\"\n",
    "    return {\n",
    "    \"AWS_PROFILE\": os.environ.get(\"AWS_PROFILE\", \"<not set>\"),\n",
    "    \"AWS_ACCESS_KEY_ID\": os.environ.get('AWS_ACCESS_KEY_ID', '<not set>'),\n",
    "    \"AWS_S3_ENDPOINT\": os.environ.get('AWS_S3_ENDPOINT', '<not set>')    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AWS_PROFILE': 'osn-renci',\n",
       " 'AWS_ACCESS_KEY_ID': '8A852VG4EG6NHHM4WUDX',\n",
       " 'AWS_S3_ENDPOINT': 'https://renc.osn.xsede.org'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myAWS_Credentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39msubmit(myAWS_Credentials)\u001b[38;5;241m.\u001b[39mresult()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "client.submit(myAWS_Credentials).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'tx00000e1d4f381c02d61b6-00640b55b5-132e6e-default',\n",
       "  'HostId': '',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-length': '0',\n",
       "   'etag': '\"d41d8cd98f00b204e9800998ecf8427e\"',\n",
       "   'accept-ranges': 'bytes',\n",
       "   'x-amz-request-id': 'tx00000e1d4f381c02d61b6-00640b55b5-132e6e-default',\n",
       "   'date': 'Fri, 10 Mar 2023 16:07:17 GMT'},\n",
       "  'RetryAttempts': 2},\n",
       " 'ETag': '\"d41d8cd98f00b204e9800998ecf8427e\"'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.submit(fsw.touch, myDir+\"write_test_2.txt\").result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rsignellbucket2/testing/gzt5142/write_test.txt']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsw.ls(myDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.6'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zarr\n",
    "zarr.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gzt5142-gzt5142-pangeo-jbook",
   "language": "python",
   "name": "conda-env-gzt5142-gzt5142-pangeo-jbook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "4100cc85ffefb381c538d28dd18cb927e5a99f05bbed6aaad5313d7bb1c2079e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
