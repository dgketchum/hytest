{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualizing CONUS404 and reference data \n",
    "\n",
    "<img src='../../../doc/assets/Eval_Viz.svg' width=600>\n",
    "The purpose of visualization notebooks is to look at data in pretty ways.\n",
    "\n",
    "<details>\n",
    "  <summary>Guide to pre-requisites and learning outcomes...&lt;click to expand&gt;</summary>\n",
    "  \n",
    "  <table>\n",
    "    <tr>\n",
    "      <td>Pre-Requisites\n",
    "      <td>To get the most out of this notebook, you should already have an understanding of these topics: \n",
    "        <ul>\n",
    "        <li>pre-req one\n",
    "        <li>pre-req two\n",
    "        </ul>\n",
    "    <tr>\n",
    "      <td>Expected Results\n",
    "      <td>At the end of this notebook, you should be able to: \n",
    "        <ul>\n",
    "        <li>outcome one\n",
    "        <li>outcome two\n",
    "        </ul>\n",
    "  </table>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conus404-drb-OSN',\n",
       " 'prism-drb-OSN',\n",
       " 'ceres-drb-OSN',\n",
       " 'crn-drb-OSN',\n",
       " 'hcn-drb-OSN']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# library imports\n",
    "import os\n",
    "import cf_xarray\n",
    "import dask\n",
    "import fsspec \n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "# import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import intake\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pygeohydro\n",
    "import sparse \n",
    "import warnings\n",
    "import xarray as xr\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# data\n",
    "# connect to HyTEST catalog\n",
    "url = 'https://raw.githubusercontent.com/hytest-org/hytest/main/dataset_catalog/hytest_intake_catalog.yml'\n",
    "cat = intake.open_catalog(url)\n",
    "\n",
    "# access tutorial catalog\n",
    "conus404_drb_cat = cat[\"conus404-drb-eval-tutorial-catalog\"]\n",
    "list(conus404_drb_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Start a Dask client using an appropriate Dask Cluster** \n",
    "This is an optional step, but can speed up data loading significantly, especially when accessing data from the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_cluster(machine):\n",
    "    ''' Helper function to configure cluster\n",
    "    '''\n",
    "    if machine == 'denali':\n",
    "        from dask.distributed import LocalCluster, Client\n",
    "        cluster = LocalCluster(threads_per_worker=1)\n",
    "        client = Client(cluster)\n",
    "    \n",
    "    elif machine == 'tallgrass':\n",
    "        from dask.distributed import Client\n",
    "        from dask_jobqueue import SLURMCluster\n",
    "        cluster = SLURMCluster(queue='cpu', cores=1, interface='ib0',\n",
    "                               job_extra=['--nodes=1', '--ntasks-per-node=1', '--cpus-per-task=1'],\n",
    "                               memory='6GB')\n",
    "        cluster.adapt(maximum_jobs=30)\n",
    "        client = Client(cluster)\n",
    "        \n",
    "    elif machine == 'local':\n",
    "        import os\n",
    "        import warnings\n",
    "        from dask.distributed import LocalCluster, Client\n",
    "        warnings.warn(\"Running locally can result in costly data transfers!\\n\")\n",
    "        n_cores = os.cpu_count() # set to match your machine\n",
    "        cluster = LocalCluster(threads_per_worker=n_cores)\n",
    "        client = Client(cluster)\n",
    "        \n",
    "    ## do we want to change this to \"esip-nebari-gateway-v0.4\"    \n",
    "    elif machine in ['esip-qhub-gateway-v0.4']:   \n",
    "        import sys, os\n",
    "        sys.path.append(os.path.join(os.environ['HOME'],'shared','users','lib'))\n",
    "        import ebdpy as ebd\n",
    "        aws_profile = 'esip-qhub'  \n",
    "        ebd.set_credentials(profile=aws_profile)\n",
    "\n",
    "        aws_region = 'us-west-2'\n",
    "        endpoint = f's3.{aws_region}.amazonaws.com'\n",
    "        ebd.set_credentials(profile=aws_profile, region=aws_region, endpoint=endpoint)\n",
    "        worker_max = 30\n",
    "        client,cluster = ebd.start_dask_cluster(profile=aws_profile, worker_max=worker_max, \n",
    "                                              region=aws_region, use_existing_cluster=True,\n",
    "                                              adaptive_scaling=True, wait_for_cluster=False, \n",
    "                                              worker_profile='Medium Worker', propagate_env=True)\n",
    "        \n",
    "    return client, cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup your client and dataset on Nebari or HPC like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'SLURM_CLUSTER_NAME' in os.environ: #USGS HPC use SLURM CLUSTER to handle jobs, otherwise...\n",
    "    machine = os.environ['SLURM_CLUSTER_NAME']\n",
    "    cluster = configure_cluster(machine)\n",
    "else:  # use the Nebari machine\n",
    "    machine = 'esip-qhub-gateway-v0.4'\n",
    "    client, cluster = configure_cluster(machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing already prepared CONUS404 data from OSN using `intake`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "users-users-pangeo",
   "language": "python",
   "name": "conda-env-users-users-pangeo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6b8b815d206080047d0881750c260f2e84eb4576ca4137e2355fa3de469693c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
